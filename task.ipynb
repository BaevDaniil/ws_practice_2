{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-hh945ATTwRi"
   },
   "source": [
    "# Зимний университет 2024. Введение в Deep learning.\n",
    "\n",
    "Лабораторная состоит из пошагового гайда по методам глубинного обучения (Deep Learning) на Python для изучение LSTM на задаче прогнозирования стоимости акций:\n",
    "\n",
    "1. Иморт необходимых пакетов\n",
    "2. Загрузка и проверка данных\n",
    "3. Нанесение данных на график\n",
    "4. Предварительная обработака данных\n",
    "5. Создание последовательностей и меток для обучения и теста\n",
    "6. Создание и обучение модели на базе LSTM\n",
    "7. Оценка эффектинвости модели\n",
    "8. Прогноз с помощью модели и визуализация\n",
    "\n",
    "Первое задание:\n",
    "На шаге 7 можно изменить параметры модели для повышения ее качества. По нему будет выстроен рейтинг.\n",
    "\n",
    "Дополнительное задание:\n",
    "Изменить модель на GRU и протестировать ее (+5 баллов).\n",
    "\n",
    "Итоговый балл считается следующим образом: рассчитывается балл за первое задание (= кол-во сдавших - местро в рейтинге + 1), к нему добавляются баллы за доп задание.\n",
    "\n",
    "По завершению каждого задания - подзывайте преподавателя для демонстрации работы.\n",
    "\n",
    "В этом ноутбуке изначально опущены результаты исполнения кода. Рекомендуется запускать (Shift+Enter) ячейки по мере просмотра документа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qNR1ljZuY-1N",
    "outputId": "20f1400e-5f85-4a33-faa8-78c50053e734"
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yl8Zef3NitD4"
   },
   "source": [
    "# Шаг 1: Импорт библиотек и настройка конфигурации\n",
    "Этот шаг включает импорт различных библиотек, необходимых для задач обработки данных, визуализации, машинного обучения и глубокого обучения.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nqBCSyx2MMr6"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from collections import defaultdict\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n",
    "\n",
    "Colour_Palette = ['#01BEFE', '#FF7D00', '#FFDD00', '#FF006D', '#ADFF02', '#8F00FF']\n",
    "sns.set_palette(sns.color_palette(Colour_Palette))\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B5flT16qixTN"
   },
   "source": [
    "# Шаг 2: Загрузка и проверка данных\n",
    "Загрузите исторические данные о ценах акций Apple Inc. (AAPL) из Yahoo Finance. Проверьте данные с помощью df.head()и , df.info()чтобы понять их структуру и содержание."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zZspovYfVx0H",
    "outputId": "f90933c7-8819-4357-cb35-821e9171f738"
   },
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "from datetime import date\n",
    "\n",
    "end_date = date.today().strftime(\"%Y-%m-%d\")\n",
    "start_date = '1990-01-01'\n",
    "\n",
    "df = yf.download('AAPL', start=start_date, end=end_date)\n",
    "\n",
    "# Inspect the data\n",
    "print(df.head())\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f9MUN6PZi5ag"
   },
   "source": [
    "# Шаг 3: Нанесение данных на график\n",
    "Определите функцию для построения графика данных с использованием линейных графиков для каждого столбца в DataFrame. Это помогает визуализировать тенденции и закономерности в данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 693
    },
    "id": "CV3e3NK1Vq4l",
    "outputId": "c797f612-1976-482c-83ea-6e08d433a964"
   },
   "outputs": [],
   "source": [
    "import matplotlib.dates as mdates\n",
    "\n",
    "def data_plot(df):\n",
    "    # Plot line charts\n",
    "    df_plot = df.copy()\n",
    "\n",
    "    ncols = 2\n",
    "    nrows = int(round(df_plot.shape[1] / ncols, 0))\n",
    "\n",
    "    fig, ax = plt.subplots(nrows=nrows, ncols=ncols, sharex=True, figsize=(14, 7))\n",
    "    for i, ax in enumerate(fig.axes):\n",
    "        sns.lineplot(data=df_plot.iloc[:, i], ax=ax)\n",
    "        ax.tick_params(axis=\"x\", rotation=30, labelsize=10, length=0)\n",
    "        ax.xaxis.set_major_locator(mdates.AutoDateLocator())\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot the data\n",
    "data_plot(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DG5ywD1QjCVi"
   },
   "source": [
    "# Шаг 4: Предварительная обработка данных\n",
    "На этом этапе мы разделяем данные на обучающие и тестовые наборы и нормализуем значения с помощью MinMaxScaler. Эта предварительная обработка необходима для подготовки данных для моделей машинного обучения\n",
    "\n",
    "- math.ceil: Используется для расчета количества точек обучающих данных (80% от общего числа данных)\n",
    "- train_data и test_data: Разделить DataFrame на обучающий и тестовый наборы\n",
    "- MinMaxScaler: Масштабирует данные до диапазона [0, 1]. Эта нормализация помогает нейронной сети сходиться быстрее"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ABpaR5QLWDkg",
    "outputId": "9837755e-dfda-4918-cbcd-d3218dfb5411"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Train test split\n",
    "training_data_len = math.ceil(len(df) * .8)\n",
    "print(training_data_len)\n",
    "\n",
    "# Splitting the dataset\n",
    "train_data = df[:training_data_len].iloc[:, :1]\n",
    "test_data = df[training_data_len:].iloc[:, :1]\n",
    "print(train_data.shape, test_data.shape)\n",
    "\n",
    "# Selecting Open Price values\n",
    "dataset_train = train_data.values\n",
    "# Reshaping 1D to 2D array\n",
    "dataset_train = np.reshape(dataset_train, (-1, 1))\n",
    "print(dataset_train.shape)\n",
    "\n",
    "# Selecting Open Price values\n",
    "dataset_test = test_data.values\n",
    "# Reshaping 1D to 2D array\n",
    "dataset_test = np.reshape(dataset_test, (-1, 1))\n",
    "print(dataset_test.shape)\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "# Scaling dataset\n",
    "scaled_train = scaler.fit_transform(dataset_train)\n",
    "print(scaled_train[:5])\n",
    "\n",
    "# Normalizing values between 0 and 1\n",
    "scaled_test = scaler.fit_transform(dataset_test)\n",
    "print(scaled_test[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7DQTuMKAjcw2"
   },
   "source": [
    "# Шаг 5: Создание последовательности и меток для обучения и тестирования\n",
    "Мы структурируем данные в последовательности для модели LSTM. Каждая последовательность содержит заданное количество временных шагов. Затем мы преобразуем данные в тензоры PyTorch, которые необходимы для ввода в модель PyTorch.\n",
    "\n",
    "- sequence_length: Количество временных шагов, на которые модель оглядывается назад, чтобы сделать прогноз (можно изменять, для повышения качества модели).\n",
    "- X_train и y_train: Массивы для хранения входных последовательностей и соответствующих им меток для обучения.\n",
    "- X_test и y_test: Массивы для тестирования данных.\n",
    "torch.tensor: Преобразует массивы numpy в тензоры PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "knLogV5XWGM0",
    "outputId": "f2ac8a13-336a-462c-e4af-c7d6fd825ea6"
   },
   "outputs": [],
   "source": [
    "# Create sequences and labels for training data\n",
    "sequence_length = 50  # Number of time steps to look back\n",
    "X_train, y_train = [], []\n",
    "for i in range(len(scaled_train) - sequence_length):\n",
    "    X_train.append(scaled_train[i:i + sequence_length])\n",
    "    y_train.append(scaled_train[i + sequence_length])  # Predicting the value right after the sequence\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "print(X_train.shape, y_train.shape)\n",
    "\n",
    "# Create sequences and labels for testing data\n",
    "sequence_length = 30  # Number of time steps to look back\n",
    "X_test, y_test = [], []\n",
    "for i in range(len(scaled_test) - sequence_length):\n",
    "    X_test.append(scaled_test[i:i + sequence_length])\n",
    "    y_test.append(scaled_test[i + sequence_length])  # Predicting the value right after the sequence\n",
    "X_test, y_test = np.array(X_test), np.array(y_test)\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "InpzrMhhyMrU"
   },
   "source": [
    "# Шаг 6: Создание и обучение модели LSTM\n",
    "Определите модель LSTM для прогнозирования временных рядов. Модель включает в себя слой LSTM, за которым следует полносвязный слой. Обучите модель на обучающих данных и оцените её на тестовых данных.\n",
    "\n",
    "- LSTMModel: класс нейронной сети PyTorch со слоем LSTM и линейным слоем.\n",
    "Конфигурация устройства: проверьте, доступен ли графический процессор, и используйте его, если возможно.\n",
    "- Гиперпараметры: такие настройки, как размер входных данных, размер скрытых данных, количество слоёв, коэффициент отбрасывания, размер пакета, скорость обучения и количество эпох (можно изменять).\n",
    "- DataLoader: утилита для пакетной обработки и перемешивания набора данных.\n",
    "Цикл обучения: цикл по набору данных в течение заданного количества эпох, выполняющий прямой и обратный проходы и обновляющий веса модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oP1QI-P2WJOO",
    "outputId": "45a19c53-a5f3-47dd-cc45-d2ee0e8debb0"
   },
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, dropout=0.2):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout)\n",
    "        self.linear = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        out = self.linear(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "input_size = 1\n",
    "num_layers = 3  # Число слоев в модели\n",
    "hidden_size = 128  # Размерность скрытого состояния\n",
    "output_size = 1\n",
    "dropout = 0.2  # Добавочный dropout для регуляризации\n",
    "\n",
    "model = LSTMModel(input_size, hidden_size, num_layers, dropout).to(device)\n",
    "loss_fn = nn.MSELoss(reduction='mean')\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)  # Learning rate\n",
    "\n",
    "batch_size = 32  # Adjusted batch size\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "num_epochs = 20  # Increased number of epochs\n",
    "train_hist = []\n",
    "test_hist = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0.0\n",
    "    model.train()\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "        predictions = model(batch_X)\n",
    "        loss = loss_fn(predictions, batch_y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    average_loss = total_loss / len(train_loader)\n",
    "    train_hist.append(average_loss)\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}] - Training Loss: {average_loss:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bR1kOCGo5Etv"
   },
   "source": [
    "График обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CNnFR4keP0zs"
   },
   "outputs": [],
   "source": [
    "x = np.linspace(1,num_epochs,num_epochs)\n",
    "plt.plot(x,train_hist,scalex=True, label=\"Training loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sX5e1i2Y0Y4J"
   },
   "source": [
    "# Шаг 7: Оцените эффективность модели с помощью таких показателей, как среднеквадратическая ошибка и коэффициент R².\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZZOzIX74z23J",
    "outputId": "f41baf6d-7933-47eb-c5f7-27e0ca9f85a5"
   },
   "outputs": [],
   "source": [
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Evaluate the model and calculate RMSE and R² score\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_predictions = []\n",
    "    for batch_X_test in X_test:\n",
    "        batch_X_test = batch_X_test.to(device).unsqueeze(0)  # Add batch dimension\n",
    "        test_predictions.append(model(batch_X_test).cpu().numpy().flatten()[0])\n",
    "\n",
    "test_predictions = np.array(test_predictions)\n",
    "\n",
    "# Calculate RMSE and R² score\n",
    "rmse = np.sqrt(mean_squared_error(y_test.cpu().numpy(), test_predictions))\n",
    "r2 = r2_score(y_test.cpu().numpy(), test_predictions)\n",
    "\n",
    "print(f'RMSE: {rmse:.4f}')\n",
    "print(f'R² Score: {r2:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q3Do7uQskYeY"
   },
   "source": [
    "# Шаг 8: Спрогнозируйте будущие значения и оцените модель\n",
    "Используйте обученную модель для прогнозирования будущих значений.\n",
    "\n",
    "- Прогнозирование: генерирование будущих значений с использованием обученной модели.\n",
    "- Построение графиков: визуализируйте фактические и прогнозируемые значения.\n",
    "\n",
    "Парматеры, которые можно поменять:\n",
    "- steps - сдвиг от конца последовательности (чем больше, тем больше пересечение с известными данными)\n",
    "- num_forecast_steps - число предсказываемых измерений (если больше, чем steps можно заглянуть в будущее)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "id": "KwCKpGj8P3jw",
    "outputId": "ee7bc34a-f9ac-4861-be7b-aca3b31e3acd"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "steps = 30\n",
    "\n",
    "num_forecast_steps = 60\n",
    "sequence_to_plot = X_test.squeeze().cpu().numpy()\n",
    "historical_data = sequence_to_plot[-steps]\n",
    "\n",
    "forecasted_values = []\n",
    "with torch.no_grad():\n",
    "    for _ in range(num_forecast_steps):\n",
    "        historical_data_tensor = torch.as_tensor(historical_data).view(1, -1, 1).float().to(device)\n",
    "        predicted_value = model(historical_data_tensor).cpu().numpy()[0, 0]\n",
    "        forecasted_values.append(predicted_value)\n",
    "        historical_data = np.roll(historical_data, shift=-1)\n",
    "        historical_data[-1] = predicted_value\n",
    "\n",
    "last_date = test_data.index[-steps]\n",
    "future_dates = pd.date_range(start=last_date + pd.DateOffset(1), periods=num_forecast_steps)\n",
    "\n",
    "forecasted_values_scaled = scaler.inverse_transform(np.array(forecasted_values).reshape(-1, 1)).flatten()\n",
    "combined_values = np.concatenate([test_data[-steps:-steps+1].values.flatten(), forecasted_values_scaled])\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [14, 4]\n",
    "plt.plot(test_data.index[-100:], test_data[-100:], label=\"test_data\", color=\"b\")\n",
    "plt.plot(test_data.index[-steps:-steps+1].append(future_dates), combined_values, label='forecasted values', color='red')\n",
    "plt.plot(test_data.index[-steps:], test_data[-steps:], label='actual values', color='green')\n",
    "\n",
    "plt.xlabel('Time Step')\n",
    "plt.ylabel('Value')\n",
    "plt.legend()\n",
    "plt.title('Time Series Forecasting')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
